---
title: "Discrete Random Variables & probability and cumulative mass functions"
output: slidy_presentation
---

# Discrete Random Variables

- A **random variable** is a numerical outcome of an experiment.

- A discrete random variable is one that can take on a countable number of values.
    - e.g. $\{0, 1 \}$ or $\{0, 1, 2, 3, 4, \ldots \}$.
    - Usually we are counting things.
    
# Probability mass function

- The *probability mass function* (or pmf) of a discrete random variable $X$ taking values in sample space $A$ is a function
$$f(x) = \Pr(X = x; x \in A)$$

- The pmf tells us the probability of all the outcomes $X$ can take.  
    - If we expand the sample space, then $f(x) = 0$ if $x \notin A$.

# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
barplot(height = c(0.5, 0.5), names.arg = c(0, 1), ylim = c(0, 1), col = "red", xlab = "x", ylab = "f(x)")
```

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
barplot(height = c(0.25, 0.5, 0.25), names.arg = c(0, 1, 3), ylim = c(0, 1), col = "red", xlab = "x", ylab = "f(x)")
```
    
# Rules for pmf's

- Must be a probability
$$0 \leq f(x) \leq 1$$

- Must cover all possibilities
$$\sum_{x \in A} f(x) = 1$$

$$f(x) = 0 \, \forall \, x \notin A$$

# Cumulutive distribution function

- The *cumulative distribution function* of a random variable $X$ is a function of $x \in \mathbb{R}$ that gives the total probability that $X$ will be at most $x$.
$$F(x) = \sum_{y \leq x} f(x)$$

- Note: pmf's will usually be in lower case and cdf's will usually be in upper case.

# Rules for cdf's

- $F( - \infty ) = 0$ 
    - (or to be more exact $\lim_{x \to -\infty} F(x) = 0$)

- $F(\infty) = 1$
    - (or to be more exact $\lim_{x \to \infty} F(x) = 1$)
    
- $F(y) \leq F(x)$ for $y < x$.

- $0 \leq F(x) \leq 1$

# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
plot(y = c(0, 0, 0.5, 0.5, 1, 1), x = c(-2, 0, 0, 1, 1, 3), type = "l", lwd = 2, ylim = c(0, 1), xlim = c(-1, 2), xlab = "x", ylab = "F(x)")
```

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
plot(y = c(0, 0, 0.25, 0.25, 0.75, 0.75, 1, 1), x = c(-2, 0, 0, 1, 1, 2, 2, 4), type = "l", lwd = 2, ylim = c(0, 1), xlim = c(-1, 3), xlab = "x", ylab = "F(x)")
```

# Expectation

- The *expectation* of a random variable $X$ is the long run average of $X$.

- Or we can think of the expectation as the probability weighted sum of the possible outcomes:
$$\mathrm{E} (X) = \sum_{x \in A} x \Pr(X = x)$$
$$= \sum_{x \in A} x f(x)$$

# Properties of expectation: Linearity

- The expectation of a sum of random variables is the sum of the expectations (independent or not).
$$\mathrm{E} (X + Y) = \mathrm{E} (X) + \mathrm{E} (Y)$$

    \

- Scaling the random variable scales the expectation accordingly.
$$\mathrm{E} (c \cdot X) = c \cdot \mathrm{E} (X), \, \text{ for } c \in \mathbb{R}$$

    \

- Combine these:
$$\mathrm{E} (c_{1} \cdot X + c_{2} \cdot Y) = c_{1} \cdot \mathrm{E} (X) + c_{2} \cdot \mathrm{E} (Y)$$

# Properties of expectation: Independence

- If two random variables are independent, then the expectation of their product is the product of their expectation.
$$\mathrm{E} (X \cdot Y) = \mathrm{E} (X) \cdot \mathrm{E} (Y) \; \text{ for } X \text{ and } Y \text{ independent.}$$

    \

- Similarly for any functions $g, h$ and independent $X$ and $Y$,
$$\mathrm{E} (g(X) \cdot h(Y)) = \mathrm{E} (g(X)) \cdot \mathrm{E} (h(Y)).$$


# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values

    \
   
- What is the expected number of heads?
$$\mathrm{E} (X) = 0 \cdot 0.5 + 1 \cdot 0.5 = 1/2$$

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
    \
   
- What is the expected number of heads?
$$\mathrm{E} (X) = 0 \cdot 0.25 + 1 \cdot 0.5  + 2 \cdot 0.25= 1$$
    
# Example: roulette wheel

- An American roulette wheel has 38 pockets, labelled $00$, $0$, $1$, $\ldots$, $36$.  The two zeros, $0$ and $00$, are colored green.  Half of the remaining numbers are colored red and half are colored black.

![](american-wheel.png)

# Example: betting on a roulette wheel

- One bet we can make is whether the color of the pocket is red or black. We win double our money if we're right, but lose it if we're wrong.

- Suppose we make a bet of $\$ 10$ on red. What is the expected value of our bet?
    - On $20$ out of the $38$ outcomes, we gain nothing.
    - On $18$ out of the $38$ outcomes, we gain $\$ 20$.
    
- Assume all pockets are equally likely.
    - pmf: $f(0) = 20/38$ and $f(20) = 18/38$
    
- Expected value: 
    - Remember we have to pay $\$ 10$ to play, so we lose that no matter what.
$$\mathrm{E}(\text{ betting on red }) = \mathrm{E}(X - 10)$$
$$= (20/38) \cdot 0 + (18/38) \cdot 20 - 10 = -0.526$$


