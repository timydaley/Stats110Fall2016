---
title: "Discrete Random Variables & probability and cumulative mass functions"
output: slidy_presentation
---

# Discrete Random Variables

- A **random variable** is a numerical outcome of an experiment.

- A discrete random variable is one that can take on a countable number of values.
    - e.g. $\{0, 1 \}$ or $\{0, 1, 2, 3, 4, \ldots \}$.
    - Usually we are counting things.
    
# Probability mass function

- The *probability mass function* (or pmf) of a discrete random variable $X$ taking values in sample space $A$ is a function
$$f(x) = \Pr(X = x; x \in A)$$

- The pmf tells us the probability of all the outcomes $X$ can take.  
    - If we expand the sample space, then $f(x) = 0$ if $x \notin A$.
    

# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
barplot(height = c(0.5, 0.5), names.arg = c(0, 1), ylim = c(0, 1), col = "red", xlab = "x", ylab = "f(x)")
```

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
barplot(height = c(0.25, 0.5, 0.25), names.arg = c(0, 1, 3), ylim = c(0, 1), col = "red", xlab = "x", ylab = "f(x)")
```
    
# Rules for pmf's

- Must be a probability
$$0 \leq f(x) \leq 1$$

- Must cover all possibilities
$$\sum_{x \in A} f(x) = 1$$

$$f(x) = 0 \, \forall \, x \notin A$$

# Cumulutive distribution function

- The *cumulative distribution function* of a random variable $X$ is a function of $x \in \mathbb{R}$ that gives the total probability that $X$ will be at most $x$.
$$F(x) = \sum_{y \leq x} f(x)$$

- Note: pmf's will usually be in lower case and cdf's will usually be in upper case.

# Rules for cdf's

- $F( - \infty ) = 0$ 
    - (or to be more exact $\lim_{x \to -\infty} F(x) = 0$)

- $F(\infty) = 1$
    - (or to be more exact $\lim_{x \to \infty} F(x) = 1$)
    
- $F(y) \leq F(x)$ for $y < x$.

- $0 \leq F(x) \leq 1$

# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
plot(y = c(0, 0, 0.5, 0.5, 1, 1), x = c(-2, 0, 0, 1, 1, 3), type = "l", lwd = 2, ylim = c(0, 1), xlim = c(-1, 2), xlab = "x", ylab = "F(x)")
```

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
```{r cache=TRUE, echo=FALSE, fig.height=5, fig.width=6}
plot(y = c(0, 0, 0.25, 0.25, 0.75, 0.75, 1, 1), x = c(-2, 0, 0, 1, 1, 2, 2, 4), type = "l", lwd = 2, ylim = c(0, 1), xlim = c(-1, 3), xlab = "x", ylab = "F(x)")
```

# Expectation

- The *expectation* of a random variable $X$ is the long run average of $X$.

- Or we can think of the expectation as the probability weighted sum of the possible outcomes:
$$\mathrm{E} (X) = \sum_{x \in A} x \Pr(X = x)$$
$$= \sum_{x \in A} x f(x)$$



# Properties of expectation: Linearity

- The expectation of a sum of random variables is the sum of the expectations (independent or not).
$$\mathrm{E} (X + Y) = \mathrm{E} (X) + \mathrm{E} (Y)$$

    \

- Scaling the random variable scales the expectation accordingly.
$$\mathrm{E} (c \cdot X) = c \cdot \mathrm{E} (X), \, \text{ for } c \in \mathbb{R}$$

    \

- Combine these:
$$\mathrm{E} (c_{1} \cdot X + c_{2} \cdot Y) = c_{1} \cdot \mathrm{E} (X) + c_{2} \cdot \mathrm{E} (Y)$$

# Properties of expectation: Independence

- If two random variables are independent, then the expectation of their product is the product of their expectation.
$$\mathrm{E} (X \cdot Y) = \mathrm{E} (X) \cdot \mathrm{E} (Y) \; \text{ for } X \text{ and } Y \text{ independent.}$$

    \

- Similarly for any functions $g, h$ and independent $X$ and $Y$,
$$\mathrm{E} (g(X) \cdot h(Y)) = \mathrm{E} (g(X)) \cdot \mathrm{E} (h(Y)).$$

# Properties of expectation: using cdf to calculate expectation

Suppose that $X$ can only take on positive values: $\{ 0, 1, 2, \ldots \}$.  How to calculate expectation using cdf?

$$\mathrm{E}(X) = \sum{x \geq 0} x f(x)$$
$$= \sum_{x \geq 1} x \Pr(X = x) = \sum_{x \geq 1} \sum_{y = 1}^{x} \Pr(X = x)$$
$$= \sum_{y \geq 1} \sum_{x = y}^{\infty} \Pr(X = x) = \sum_{y \geq 1} \Pr(X \geq y)$$
$$= \sum_{y \geq 1} 1 - F(y)$$


# Examples

- Suppose you flip a coin and you count the number of heads.

- One flip: 
    - $A = \{0, 1 \}$ 
    - $f(0) = 0.5$, $\; f(1) = 0.5$, and $= 0$ for all other values

    \
   
- What is the expected number of heads?
$$\mathrm{E} (X) = 0 \cdot 0.5 + 1 \cdot 0.5 = 1/2$$

# Examples

- Suppose you flip a coin and you count the number of heads.

- Two flips:
    - $A = \{0, 1, 2 \}$
    - $f(0) = 0.25$, $\; f(1) = 0.5$, and $f(2) = 0.25$
    
    \
   
- What is the expected number of heads?
$$\mathrm{E} (X) = 0 \cdot 0.25 + 1 \cdot 0.5  + 2 \cdot 0.25= 1$$
    
# Example: roulette wheel

- An American roulette wheel has 38 pockets, labelled $00$, $0$, $1$, $\ldots$, $36$.  The two zeros, $0$ and $00$, are colored green.  Half of the remaining numbers are colored red and half are colored black.

![](american-wheel.png)

# Example: betting on a roulette wheel

- One bet we can make is whether the color of the pocket is red or black. We win double our money if we're right, but lose it if we're wrong.

- Suppose we make a bet of $\$ 10$ on red. What is the expected value of our bet?
    - On $20$ out of the $38$ outcomes, we gain nothing.
    - On $18$ out of the $38$ outcomes, we gain $\$ 20$.
    
- Assume all pockets are equally likely.
    - pmf: $f(0) = 20/38$ and $f(20) = 18/38$
    
- Expected value: 
    - Remember we have to pay $\$ 10$ to play, so we lose that no matter what.
$$\mathrm{E}(\text{ betting on red }) = \mathrm{E}(X - 10)$$
$$= (20/38) \cdot 0 + (18/38) \cdot 20 - 10 = -0.526$$

# Example: The proper price of making a flush with one card to come?

Suppose we've seen 6 cards and we have four to a flush (5 cards of the same suit).  The current pot is $20.  If our opponent bets, what price can he bet that is break even for making a flush?

We want to calculate the cost $C$ such that 
$$\mathrm{E} (\text{call}) = - C + \Pr(\text{flush}) \cdot (20 + 2 \cdot C) = 0$$

# Example: The proper price of making a flush with one card to come?

First:  What's the probability of making the flush?

- We've seen 4 cards of the suit, $13 - 4 = 9$ remaining.

- Total number of cards remaining: $52 - 6 = 46$ remaining

$$\Pr (\text{ flush }) = \frac{9}{46} \approx 0.195$$

# Example: The proper price of making a flush with one card to come?

Now to calculate $C$.

$$-C + \frac{9}{46} \cdot(20 + 2 \cdot C) = 0$$
$$\frac{180}{46} + C \cdot \bigg(\frac{18}{46} - 1 \bigg) = 0$$
$$\frac{180}{46} = \frac{28}{46} C$$
$$C = \frac{180}{28} \approx 6.43$$

So if our opponent bets $6.5 or more, calling for the flush would not be profitable.

# Variance {.bigger}

# Variance

**Variance** is a measure of variation or dispersion.  It specifically measures the squared deviation from the mean.

$$\mathrm{Var}(X) = \sigma_{X}^{2} = \mathrm{E}(X - \mathrm{E}(X))^{2}$$

The **standard deviation** is the square root of the variance.  Note that the standard deviation has the same units as $X$.  

$$\sigma_{X} = \sqrt{\mathrm{Var}(X)}$$

# Properties of variance: 

- invariant to translation (shifts)
$$\mathrm{Var}(X + c) = \mathrm{E} \big(X + c - \mathrm{E}(X + c) \big)^{2}$$
$$= \mathrm{E} \big(X + c - \mathrm{E}(X) - c \big)^{2}$$
$$= \mathrm{E} \big(X - \mathrm{E}(X) \big)^{2}$$

- scaling $X$ scales the variance quadratically
$$\mathrm{Var}(c \cdot X) = \mathrm{E} \big(c \cdot X - \mathrm{E}(c \cdot X) \big)^{2}$$
$$= \mathrm{E} \big(c \cdot X - c \cdot \mathrm{E}(X) \big)^{2}$$
$$= c^{2} \cdot \mathrm{E} (X - \mathrm{E}(X)) = c^{2} \mathrm{Var} (X)$$
    - scaling $X$ scales the standard deviation

# Properties of variance: difference of squared expectations

$$\mathrm{Var}(X) = \mathrm{E}(X - \mathrm{E}(X))^{2}$$
$$= \mathrm{E} \big(X^{2} - 2 \cdot X \cdot \mathrm{E}(X) + (\mathrm{E}(X))^{2} \big)$$
$$= \mathrm{E} (X^{2}) - 2 \mathrm{E}(X) \mathrm{E}(X) + (\mathrm{E}(X))^{2}$$
$$= \mathrm{E} (X^{2}) - (\mathrm{E}(X))^{2}$$

This sometimes eases the calculations.

# Example: What's the variance in betting $10 on red in roulette?

$$\mathrm{Var}(X) = \frac{20}{38} (-10 - (-0.526))^{2} + \frac{18}{38}(10 - (-0.526))^{2}$$
$$= 47.24 + 52.48 = 99.72$$

$$\sigma_{X} = 9.986$$
