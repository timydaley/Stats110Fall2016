---
title: "Variance, sample variance, and sample mean"
output:
  beamer_presentation:
    increment: true
date: October 4, 2016
author: Timothy Daley
---

# Variance {.bigger}

# Variance

- **Variance** is a measure of variation or dispersion.  It specifically measures the squared deviation from the mean.
$$\mathrm{Var}(X) = \sigma_{X}^{2} = \mathrm{E}(X - \mathrm{E}(X))^{2}$$

- The **standard deviation** is the square root of the variance.  Note that the standard deviation has the same units as $X$.  
$$\sigma_{X} = \sqrt{\mathrm{Var}(X)}$$

# Properties of variance: invariant to shift

- invariant to translation (shifts)
$$\mathrm{Var}(X + c) = \mathrm{E} \big(X + c - \mathrm{E}(X + c) \big)^{2}$$
$$= \mathrm{E} \big(X + c - \mathrm{E}(X) - c \big)^{2}$$
$$= \mathrm{E} \big(X - \mathrm{E}(X) \big)^{2}$$

# Properties of variance: scaling

- scaling $X$ scales the variance quadratically
$$\mathrm{Var}(c \cdot X) = \mathrm{E} \big(c \cdot X - \mathrm{E}(c \cdot X) \big)^{2}$$
$$= \mathrm{E} \big(c \cdot X - c \cdot \mathrm{E}(X) \big)^{2}$$
$$= c^{2} \cdot \mathrm{E} (X - \mathrm{E}(X)) = c^{2} \mathrm{Var} (X)$$
    - scaling $X$ scales the standard deviation linearly

# Properties of variance: difference of squared expectations

$$\mathrm{Var}(X) = \mathrm{E}(X - \mathrm{E}(X))^{2}$$
$$= \mathrm{E} \big(X^{2} - 2 \cdot X \cdot \mathrm{E}(X) + (\mathrm{E}(X))^{2} \big)$$
$$= \mathrm{E} (X^{2}) - 2 \mathrm{E}(X) \mathrm{E}(X) + (\mathrm{E}(X))^{2}$$
$$= \mathrm{E} (X^{2}) - (\mathrm{E}(X))^{2}$$

This sometimes eases the calculations.

# Why squared deviation?

Why do we measure deviation from mean in average square deviation?

- Historically, taking square deviation makes life easier since you can take derivatives of square deviation.

- $\min_{c} \mathrm{E} (X - c)^{2}$

- $\frac{\partial}{\partial c} \mathrm{E} (X - c)^{2} = \mathrm{E} 2(X - c)$ 

- $\Rightarrow$ $c = \mathrm{E} X$.

# Example: FLipping a coin

- Flip a coin and let $X$ be the number of heads.

- $\mathrm{E} X = \frac{1}{2}$

- $\mathrm{E} X^{2} = 0^{2} \cdot \frac{1}{2} + 1^{2} \cdot \frac{1}{2} = \frac{1}{2}$

- $\mathrm{Var} (X) = \mathrm{E} X^{2} - (\mathrm{E} X)^{2} = 1/2 - (1/2)^{2} = 1/4$.

# Example: Flipping two coins

- Flip a coin twice and let $X$ be the number of heads.

- $\mathrm{E} X = 1$

- $\mathrm{Var} (X) = \sum_{x = 0}^{2} (x - \mathrm{E} X)^{2} \Pr(X = x)$
$$= (0 - 1)^{2} \cdot 0.25 + (1 - 1)^{2} \cdot 0.5 + (2 - 1)^{2} \cdot 0.25 = 1/2$$


# Example: What's the variance in betting $10 on red in roulette?

- Recall that $\mathrm{E} X = -0.526$, $\Pr(X = 0) = 20/38$, and $\Pr(X = 20) = 18/38$

- $\mathrm{Var}(X) = \frac{20}{38} (-10 - (-0.526))^{2} + \frac{18}{38}(10 - (-0.526))^{2}$
$$= 47.24 + 52.48 = 99.72$$
$$\sigma_{X} = 9.986$$


# Estimating mean and variance {.bigger}

# Estimating the mean 

- The **sample mean** is the average of the observations.

- If the observations are $x_{1}, x_{2}, \ldots, x_{n}$ then the sample mean is $$\bar{x} = \frac{x_{1} + x_{2} + \cdots + x_{n}}{n}$$.

# Estimating the variance

- The **sample variance** is the average squared deviation of the observations from the sample mean.

- $$\hat{\sigma}^{2} = \frac{1}{n} \bigg( (x_{1} - \bar{x})^{2} + \cdots + (x_{n} - \bar{x})^{2} \bigg)$$

- $$\hat{\sigma}^{2} = \bigg(\frac{1}{n} \sum_{i = 1}^{n} x_{i}^{2} \bigg) - \bar{x}^{2}$$

# Example:

- Suppose you have \$ 100 to bet on roulette.  You make ten \$ 10 bets and you win 4 times and lose 6.  What's the average outcome and variance?

- Sample = $\{10, 10, 10, 10, -10, -10, -10, -10, -10, -10 \}$

- $\bar{x} = (4 \cdot 10 + 6 \cdot (- 10))/10 = -2$

# Example cont:

$$\hat{\sigma}^{2} = \frac{1}{10} \big( 4 \cdot (10 - (-2))^{2} + 6 \cdot (-10 - (-2))^{2} \big)$$
$$= \frac{1}{10} \big(4 \cdot 144 + 6 \cdot 64) = \frac{960}{10} = 96$$
$$\hat{\sigma} = 9.798$$

# Example: rolling die

Suppose we roll a 6-sided die 20 times.  We get the following outcomes:
```{r cache=TRUE}
x = sample(1:6, 20, replace = TRUE)
x
```

The sample mean is 
```{r}
mean(x)
```

# Example cont.

The sample sd is
```{r}
sd(x)
```


# Example: Simulating roulette outcomes.

Suppose we have $100 to bring to the casino. Suppose we leave either after we win $100 or lose the $100 that we brought.  We want to know how much time we will spend there. 

This is currently too complicated for us to do in practice, so we will simulate the process.

# Example: Simulating roulette outcomes.

```{r cache=TRUE}
n_sim = 1000
t = rep(0, times = n_sim)
for(i in 1:1000){
  money = 100
  while(money < 200 & money > 0){
    if(rbinom(1, 1, 18/38) > 0){
      money = money + 10
    }
    else{
      money = money - 10
    }
    t[i] = t[i] + 1
  }
}
```

# Example: Simulating roulette outcomes.

```{r cache=TRUE, fig.height=2.5, fig.width=3.5}
t_mean = mean(t)
t_mean
t_sd = sd(t)
t_sd
```

# Example: Simulating roulette outcomes.

```{r cache=TRUE, fig.height=3, fig.width=4}
hist(t, breaks = 20)
abline(v = t_mean, lty = 2, lwd = 2)
abline(v = t_mean - t_sd, lty = 3, lwd = 2)
abline(v = t_mean + t_sd, lty = 3, lwd = 2)
legend("topright", legend = c("mean", "mean +- sd"), lty = c(2, 3))
```
